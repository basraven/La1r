
# apiVersion defines the version of the charts.yaml structure. Currently,
# only "v1" is supported.
apiVersion: v1

# name is the .Release.Name template value that charts can use in their
# templates, which can be overridden by the "--name" CLI flag. If omitted,
# "--name" is required.
name: spark

# namespace is the .Release.Namespace template value that charts can use in
# their templates. Note that since kubecrt does not communicate with
# Kubernetes in any way, it is up to you to also use this namespace when
# doing kubectl apply [...]. Can be overridden using "--namespace".  If omitted,
# "--namespace" is required.
namespace: apps

# charts is an array of charts you want to compile into Kubernetes resource
# files.
#
# A single chart might be used to deploy something simple, like a memcached pod,
# or something complex, like a full web app stack with HTTP servers, databases,
# caches, and so on.
charts:

# A Chart can either be in the format REPO/NAME, or a PATH to a local chart.
#
# If using REPO/NAME, kubecrt knows by-default where to locate the "stable"
# repository, all other repositories require the "repo" configuration (see
# below).
- incubator/sparkoperator:
    # repo is the location of a repositry, if other than "stable". This is
    # the URL you would normally add using "helm repo add NAME URL".
    repo: http://storage.googleapis.com/kubernetes-charts-incubator
    # values is a map of key/value pairs used when compiling the chart. This
    # uses the same format as in regular chart "values.yaml" files.
    #
    # see: https://git.io/v9Tyr
    values:
      operatorImageName: gcr.io/spark-operator/spark-operator
      operatorVersion: v1beta2-1.0.1-2.4.4
      imagePullPolicy: IfNotPresent
      imagePullSecrets: []
      replicas: 1

      rbac:
        create: true

      serviceAccounts:
        spark:
          create: true
          name:
        sparkoperator:
          create: true
          name:

      sparkJobNamespace: ""
      installCrds: true
      controllerThreads: 10
      resyncInterval: 30
      ingressUrlFormat: ""
      logLevel: 2

      securityContext: {}

      enableWebhook: false
      webhookPort: 8080

      enableMetrics: true
      metricsPort: 10254
      metricsEndpoint: "/metrics"
      metricsPrefix: ""

      ## Node labels for pod assignment
      ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
      ##
      nodeSelector: {}

      podAnnotations: {}

      ## Resources for the sparkoperator deployment
      ## Ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
      ##
      resources: {}

      ## Whether to enable batch scheduler for pod scheduling,
      ## if enabled, end user can specify batch scheduler name in spark application.
      enableBatchScheduler: false

      ## Whether to enable the ResourceQuota enforcement for SparkApplication resources.
      ## Requires the webhook to be enabled by setting enableWebhook to true.
      ## Ref: https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#enabling-resource-quota-enforcement.
      enableResourceQuotaEnforcement: false

      ## Whether to enable leader election when the operator Deployment has more than one replica.
      ## Only applicable when `replicas` is set to a value greater than 1.
      ## Ref: https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md#enabling-leader-election-for-high-availability.
      enableLeaderElection: false