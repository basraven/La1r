{"paragraphs":[{"text":"%md\n# Setup","user":"anonymous","dateUpdated":"2020-02-14T12:58:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Setup</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1581685126078_1891485311","id":"20200214-125846_506747891","dateCreated":"2020-02-14T12:58:46+0000","dateStarted":"2020-02-14T12:58:52+0000","dateFinished":"2020-02-14T12:58:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:237"},{"text":"%sh\nexport SPARK_VERSION=2.4.5\nexport HADOOP_VERSION=2.7\nexport SPARK_HOME=/opt/spark\nexport PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n\ncurl -O \"https://www-eu.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz\"\ntar xf \"spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz\"\nmv \"spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION/\" \"$SPARK_HOME\" \n\n# SPARK_SUBMIT_OPTIONS --packages org.apache.spark:spark-sql-kafka-0-10_2.12:2.4.5 kafka-clients-2.0.0.jar\n\n#SPARK_SUBMIT_OPTIONS --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5","user":"anonymous","dateUpdated":"2020-02-14T14:03:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{"SPARK_VERSION":"","HADOOP_VERSION":"","HADOOP_VERSION.tgz\" ; tar xf spark-${SPARK_VERSION":""},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  1  221M    1 3680k    0     0  3477k      0  0:01:05  0:00:01  0:01:04 3478k\r  4  221M    4 9600k    0     0  4631k      0  0:00:49  0:00:02  0:00:47 4630k\r  6  221M    6 15.1M    0     0  5066k      0  0:00:44  0:00:03  0:00:41 5066k\r  9  221M    9 20.8M    0     0  5273k      0  0:00:43  0:00:04  0:00:39 5272k\r 12  221M   12 26.6M    0     0  5401k      0  0:00:42  0:00:05  0:00:37 5478k\r 14  221M   14 32.4M    0     0  5470k      0  0:00:41  0:00:06  0:00:35 5891k\r 17  221M   17 38.2M    0     0  5546k      0  0:00:40  0:00:07  0:00:33 5926k\r 19  221M   19 43.9M    0     0  5588k      0  0:00:40  0:00:08  0:00:32 5907k\r 22  221M   22 49.7M    0     0  5621k      0  0:00:40  0:00:09  0:00:31 5904k\r 25  221M   25 55.5M    0     0  5651k      0  0:00:40  0:00:10  0:00:30 5904k\r 27  221M   27 61.2M    0     0  5675k      0  0:00:40  0:00:11  0:00:29 5924k\r 30  221M   30 67.0M    0     0  5688k      0  0:00:39  0:00:12  0:00:27 5889k\r 32  221M   32 72.7M    0     0  5702k      0  0:00:39  0:00:13  0:00:26 5886k\r 35  221M   35 78.4M    0     0  5716k      0  0:00:39  0:00:14  0:00:25 5888k\r 37  221M   37 84.2M    0     0  5727k      0  0:00:39  0:00:15  0:00:24 5881k\r 40  221M   40 90.0M    0     0  5739k      0  0:00:39  0:00:16  0:00:23 5880k\r 43  221M   43 95.7M    0     0  5750k      0  0:00:39  0:00:17  0:00:22 5897k\r 45  221M   45  101M    0     0  5757k      0  0:00:39  0:00:18  0:00:21 5899k\r 48  221M   48  107M    0     0  5766k      0  0:00:39  0:00:19  0:00:20 5907k\r 50  221M   50  113M    0     0  5771k      0  0:00:39  0:00:20  0:00:19 5903k\r 53  221M   53  118M    0     0  5778k      0  0:00:39  0:00:21  0:00:18 5904k\r 56  221M   56  124M    0     0  5785k      0  0:00:39  0:00:22  0:00:17 5907k\r 58  221M   58  130M    0     0  5791k      0  0:00:39  0:00:23  0:00:16 5916k\r 61  221M   61  136M    0     0  5796k      0  0:00:39  0:00:24  0:00:15 5912k\r 64  221M   64  141M    0     0  5796k      0  0:00:39  0:00:25  0:00:14 5898k\r 66  221M   66  147M    0     0  5801k      0  0:00:39  0:00:26  0:00:13 5896k\r 69  221M   69  153M    0     0  5806k      0  0:00:39  0:00:27  0:00:12 5897k\r 71  221M   71  159M    0     0  5811k      0  0:00:39  0:00:28  0:00:11 5904k\r 74  221M   74  165M    0     0  5816k      0  0:00:39  0:00:29  0:00:10 5911k\r 77  221M   77  170M    0     0  5819k      0  0:00:39  0:00:30  0:00:09 5936k\r 79  221M   79  176M    0     0  5822k      0  0:00:38  0:00:31  0:00:07 5933k\r 82  221M   82  182M    0     0  5823k      0  0:00:38  0:00:32  0:00:06 5915k\r 84  221M   84  188M    0     0  5828k      0  0:00:38  0:00:33  0:00:05 5923k\r 87  221M   87  193M    0     0  5829k      0  0:00:38  0:00:34  0:00:04 5904k\r 90  221M   90  199M    0     0  5832k      0  0:00:38  0:00:35  0:00:03 5910k\r 92  221M   92  205M    0     0  5833k      0  0:00:38  0:00:36  0:00:02 5899k\r 95  221M   95  211M    0     0  5833k      0  0:00:38  0:00:37  0:00:01 5900k\r 97  221M   97  216M    0     0  5837k      0  0:00:38  0:00:38 --:--:-- 5894k\r100  221M  100  221M    0     0  5836k      0  0:00:38  0:00:38 --:--:-- 5888k\n"}]},"apps":[],"jobName":"paragraph_1581681573075_51648794","id":"20200214-115933_564297473","dateCreated":"2020-02-14T11:59:33+0000","dateStarted":"2020-02-14T13:46:49+0000","dateFinished":"2020-02-14T13:47:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:238"},{"text":"%spark.conf\nSPARK_HOME /opt/spark\n\nSPARK_EXECUTOR_MEMORY 4G\nSPARK_EXECUTOR_CORES 1\nzeppelin.spark.pyspark.useIPython true\nmaster spark://spark-master:7077\nzeppelin.spark.uiWebUrl http://spark.bas\n\n\n\nPYSPARK_PYTHON /usr/bin/python3\nspark.pyspark.python  /usr/bin/python3","user":"anonymous","dateUpdated":"2020-02-14T14:04:04+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1581682520429_1126205107","id":"20200214-121520_1066606090","dateCreated":"2020-02-14T12:15:20+0000","dateStarted":"2020-02-14T14:04:04+0000","dateFinished":"2020-02-14T14:04:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:239"},{"text":"%sh\ncd /tmp\ncurl -O \"https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.11/2.5.0/spark-sql-kafka-0-10_2.11-2.4.5.jar\"\ncurl -O \"https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.4.0/kafka-clients-2.4.0.jar\"\ncurl -O \"https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar\"\ncurl -O \"https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar\"\ncurl -O \"https://repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar\"\ncurl -O \"https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar\"\n","user":"anonymous","dateUpdated":"2020-02-14T14:05:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   554  100   554    0     0   1025      0 --:--:-- --:--:-- --:--:--  1024\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 89 3190k   89 2866k    0     0  4301k      0 --:--:-- --:--:-- --:--:-- 4297k\r100 3190k  100 3190k    0     0  4434k      0 --:--:-- --:--:-- --:--:-- 4431k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 40509  100 40509    0     0   249k      0 --:--:-- --:--:-- --:--:--  250k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1971k  100 1971k    0     0  3915k      0 --:--:-- --:--:-- --:--:-- 3919k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  361k  100  361k    0     0  1831k      0 --:--:-- --:--:-- --:--:-- 1834k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2777  100  2777    0     0  17599      0 --:--:-- --:--:-- --:--:-- 17575\n"}]},"apps":[],"jobName":"paragraph_1581686412563_-2115655848","id":"20200214-132012_1125309151","dateCreated":"2020-02-14T13:20:12+0000","dateStarted":"2020-02-14T14:05:15+0000","dateFinished":"2020-02-14T14:05:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:240"},{"text":"%spark.dep\nz.load(\"/tmp/spark-sql-kafka-0-10_2.11-2.4.5.jar\")\nz.load(\"/tmp/kafka-clients-2.4.0.jar\")\nz.load(\"/tmp/lz4-java-1.4.0.jar\")\nz.load(\"/tmp/snappy-java-1.1.7.1.jar\")\nz.load(\"/tmp/unused-1.0.0.jar\")\nz.load(\"/tmp/slf4j-api-1.7.16.jar\")","user":"anonymous","dateUpdated":"2020-02-14T14:05:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.sonatype.aether.impl.internal.DefaultRepositorySystem.resolveDependencies(DefaultRepositorySystem.java:352)\n\tat org.apache.zeppelin.spark.dep.SparkDependencyContext.fetchArtifactWithDep(SparkDependencyContext.java:171)\n\tat org.apache.zeppelin.spark.dep.SparkDependencyContext.fetch(SparkDependencyContext.java:121)\n\tat org.apache.zeppelin.spark.DepInterpreter.interpret(DepInterpreter.java:247)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:632)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1581686403825_-180146673","id":"20200214-132003_205914479","dateCreated":"2020-02-14T13:20:03+0000","dateStarted":"2020-02-14T14:05:23+0000","dateFinished":"2020-02-14T14:05:24+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:241"},{"text":"%dep\r\nz.reset()\r\nz.addRepo(\"MavenCentral\").url(\"https://mvnrepository.com/\")\r\nz.load(\"org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.5\")\r\nz.load(\"org.apache.kafka:kafka-clients:2.4.0\")","user":"anonymous","dateUpdated":"2020-02-14T14:04:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581686844257_762174417","id":"20200214-132724_1737682184","dateCreated":"2020-02-14T13:27:24+0000","dateStarted":"2020-02-14T14:04:11+0000","dateFinished":"2020-02-14T14:04:24+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:242","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.NullPointerException\n\tat org.sonatype.aether.impl.internal.DefaultRepositorySystem.resolveDependencies(DefaultRepositorySystem.java:352)\n\tat org.apache.zeppelin.spark.dep.SparkDependencyContext.fetchArtifactWithDep(SparkDependencyContext.java:171)\n\tat org.apache.zeppelin.spark.dep.SparkDependencyContext.fetch(SparkDependencyContext.java:121)\n\tat org.apache.zeppelin.spark.DepInterpreter.interpret(DepInterpreter.java:247)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:632)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]}},{"text":"%md\n# Experiments","user":"anonymous","dateUpdated":"2020-02-14T12:58:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Experiments</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1581685113049_1703695544","id":"20200214-125833_1582754612","dateCreated":"2020-02-14T12:58:33+0000","dateStarted":"2020-02-14T12:58:41+0000","dateFinished":"2020-02-14T12:58:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:243"},{"text":"%sh\n# rm -rf tut\n# curl -O https://hackers-content.nyc3.digitaloceanspaces.com/spark-streaming/spark-streaming-sample-data.zip\n# unzip spark-streaming-sample-data.zip -d tut/\n# rm -rf tut/__*\n\n\ncat conf/zeppelin-env.sh.template","user":"anonymous","dateUpdated":"2020-02-14T13:06:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1581684281747_-1650698957","id":"20200214-124441_589531710","dateCreated":"2020-02-14T12:44:41+0000","dateStarted":"2020-02-14T13:06:09+0000","dateFinished":"2020-02-14T13:06:09+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:244"},{"text":"%spark.pyspark\nspark = SparkSession \\\n    .builder \\\n    .appName(\"StructuredNetworkWordCount\") \\\n    .getOrCreate()\n    \n# Subscribe to 1 topic\ndf = spark \\\n  .readStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", \"kafka.event.svc.cluster.local:9092\") \\\n  .option(\"subscribe\", \"taxirides\").load()\n\n","user":"anonymous","dateUpdated":"2020-02-14T13:51:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\u001b[0;31m\u001b[0m\n\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)\n\u001b[0;32m<ipython-input-10-19787dccfdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Subscribe to 1 topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mreadStream\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka.bootstrap.servers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kafka.event.svc.cluster.local:9092\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subscribe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"taxirides\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\n\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o104.load.\n: java.util.ServiceConfigurationError: org.apache.spark.sql.sources.DataSourceRegister: Provider org.apache.spark.sql.kafka010.KafkaSourceProvider could not be instantiated\n\tat java.util.ServiceLoader.fail(ServiceLoader.java:232)\n\tat java.util.ServiceLoader.access$100(ServiceLoader.java:185)\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:384)\n\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)\n\tat java.util.ServiceLoader$1.next(ServiceLoader.java:480)\n\tat scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)\n\tat scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)\n\tat scala.collection.AbstractTraversable.filter(Traversable.scala:104)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:630)\n\tat org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:161)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NoSuchMethodError: org.apache.spark.internal.Logging.$init$(Lorg/apache/spark/internal/Logging;)V\n\tat org.apache.spark.sql.kafka010.KafkaSourceProvider.<init>(KafkaSourceProvider.scala:44)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat java.lang.Class.newInstance(Class.java:442)\n\tat java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:380)\n\t... 23 more\n"}]},"apps":[],"jobName":"paragraph_1581684638420_-1624190658","id":"20200214-125038_2003189182","dateCreated":"2020-02-14T12:50:38+0000","dateStarted":"2020-02-14T13:51:19+0000","dateFinished":"2020-02-14T13:51:19+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:245"},{"text":"%spark.pyspark\r\nfrom pyspark.sql import SparkSession\r\nfrom pyspark.sql.functions import explode\r\nfrom pyspark.sql.functions import split\r\n\r\nspark = SparkSession \\\r\n    .builder \\\r\n    .appName(\"StructuredNetworkWordCount\") \\\r\n    .getOrCreate()","user":"anonymous","dateUpdated":"2020-02-14T12:56:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1581684819739_-768636267","id":"20200214-125339_450431999","dateCreated":"2020-02-14T12:53:39+0000","dateStarted":"2020-02-14T12:56:42+0000","dateFinished":"2020-02-14T12:56:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:246"},{"text":"%sh\nnc -lk 9999","user":"anonymous","dateUpdated":"2020-02-14T12:59:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\n"},{"type":"TEXT","data":"ExitValue: 1"}]},"apps":[],"jobName":"paragraph_1581685030980_1817474757","id":"20200214-125710_972074894","dateCreated":"2020-02-14T12:57:10+0000","dateStarted":"2020-02-14T12:59:23+0000","dateFinished":"2020-02-14T13:00:23+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:247"},{"text":"%sh\n/opt/spark-submit examples/src/main/python/sql/streaming/structured_network_wordcount.py localhost 9999","user":"anonymous","dateUpdated":"2020-02-14T13:00:00+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"bash: /opt/spark-submit: No such file or directory\n"},{"type":"TEXT","data":"ExitValue: 127"}]},"apps":[],"jobName":"paragraph_1581685190033_257465144","id":"20200214-125950_366144373","dateCreated":"2020-02-14T12:59:50+0000","dateStarted":"2020-02-14T13:00:00+0000","dateFinished":"2020-02-14T13:00:00+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:248"},{"text":"%pyspark\nprint(\"atoch\")\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n  .appName(\"Spark Structured Streaming from Kafka\") \\\n  .getOrCreate()\n\nsdfRides = spark \\\n  .readStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n  .option(\"subscribe\", \"taxirides\") \\\n  .option(\"startingOffsets\", \"latest\") \\\n  .load() \\\n  .selectExpr(\"CAST(value AS STRING)\") \n\nsdfFares = spark \\\n  .readStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n  .option(\"subscribe\", \"taxifares\") \\\n  .option(\"startingOffsets\", \"latest\") \\\n  .load() \\\n  .selectExpr(\"CAST(value AS STRING)\")","user":"anonymous","dateUpdated":"2020-02-14T12:10:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"atoch\n"}]},"apps":[],"jobName":"paragraph_1579636032448_-125457932","id":"20200121-194712_1881892494","dateCreated":"2020-01-21T19:47:12+0000","dateStarted":"2020-02-14T12:08:29+0000","dateFinished":"2020-02-14T12:09:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:249"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579636891747_1019245800","id":"20200121-200131_749628088","dateCreated":"2020-01-21T20:01:31+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:250"}],"name":"Spark setup notebook","id":"2EZDDX7RR","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}